{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 14499775,
          "sourceType": "datasetVersion",
          "datasetId": 9261337
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "import os\n\nos.chdir('/kaggle/working')\n\nREPO_NAME = \"Project-PlotArmor\"\nREPO_PATH = f\"/kaggle/working/{REPO_NAME}\"\nREPO_URL = \"https://github.com/nileshcharan24/Project-PlotArmor.git\"\n\nif os.path.exists(REPO_PATH):\n    print(\"ðŸ”„ Repo exists. Pulling latest changes...\")\n    os.chdir(REPO_PATH)\n    !git pull origin main\n    os.chdir('/kaggle/working')\nelse:\n    print(\"ðŸ“¥ Repo not found. Cloning fresh...\")\n    !git clone {REPO_URL}\n\nos.chdir(REPO_PATH)\nprint(f\"âœ… Current Working Directory: {os.getcwd()}\")\nprint(\"DONE\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "!pip install -r requirements.txt\nprint(\"DONE\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "# Download TinyStories dataset for real training\n!python tools/download_data.py\nprint(\"Data downloaded\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "# Pre-tokenize to memmap to avoid re-encoding on each run\n!python tools/pre_tokenize.py --input research/data/tinystories_train.txt --output research/data/tinystories_train.bin --chunk_lines 10000\nprint(\"Pretokenization complete\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "import sys\nsys.path.append('.')\n\n# Use long training config\nfrom research.config.kaggle_long_train import KAGGLE_LONG_CONFIGS\n\n# Override defaults\nimport argparse\nargs = argparse.Namespace(\n    model='bdh',  # or 'gpt2'\n    data_path='research/data/tinystories_train.txt',\n    pretokenized_path='research/data/tinystories_train.bin',\n    max_steps=KAGGLE_LONG_CONFIGS['bdh']['max_steps'],\n    batch_size=KAGGLE_LONG_CONFIGS['bdh']['batch_size'],\n    val_interval=500,\n    gen_interval=500\n)\n\n# Monkey patch sys.argv for parser\nsys.argv = ['train.py'] + [f'--{k}={v}' for k, v in vars(args).items() if not k.startswith('_')]\nprint(\"DEBUG: sys.argv set\")\n\nfrom research.utils.train import main\nprint(\"DEBUG: main imported\")\nprint(\"DEBUG: Starting training...\")\nmain()\nprint(\"DONE\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "# Files are automatically copied to /kaggle/working/ after training\n# Download them from Kaggle's output panel\nimport os\nprint(\"Available downloads:\")\nfor f in os.listdir('/kaggle/working'):\n    if f.endswith('.csv') or f.endswith('.pt'):\n        print(f\"- {f}\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport glob\n\n# Find the latest CSV in /kaggle/working/\ncsv_files = glob.glob('/kaggle/working/training_log_*.csv')\nif csv_files:\n    latest_csv = max(csv_files, key=os.path.getctime)\n    print(f\"Plotting from: {latest_csv}\")\n    \n    df = pd.read_csv(latest_csv)\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # Loss curves\n    ax1.plot(df['step'], df['train_loss'], label='Train Loss')\n    ax1.plot(df['step'], df['val_loss'], label='Val Loss')\n    ax1.set_xlabel('Step')\n    ax1.set_ylabel('Loss')\n    ax1.set_title('Training and Validation Loss')\n    ax1.legend()\n    ax1.grid(True)\n    \n    # Perplexity curve\n    ax2.plot(df['step'], df['perplexity'], color='orange')\n    ax2.set_xlabel('Step')\n    ax2.set_ylabel('Perplexity')\n    ax2.set_title('Perplexity Over Time')\n    ax2.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/training_curve.png')\n    plt.show()\n    \n    print(\"Plot saved to /kaggle/working/training_curve.png - download it!\")\nelse:\n    print(\"No CSV files found in /kaggle/working/\")\n",
      "outputs": [],
      "execution_count": null
    }
  ]
}
